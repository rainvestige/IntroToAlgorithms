2.1-3 linear search
output = NIL
for i = 1 to A.length:   n+1
    if A[i] == v:        n
        output = i       1
        break            1
    // The following two lines can be dropped.
    else:                
        output = NIL     n-1


2.1-4
d = 0
for i = 1 to A.length:
    C[i] = (A[i] + B[i]) % 2  // modulus
    d = (A[i] + B[i]) / 2     // divide
    C[i+1] = d


2.2-1
theta(n^3)


2.2-2 selection sort
for i = 1 to (A.length - 1):        n-1+1
    smallest = A[i]                 n-1
    idx = i                         n-1
    for j = i+1 to A.length:        (n-1)(n+2)(n-1)/2
        // find the smallest item   0
        if A[j] < smallest:         (n-1)(n+2)(n-1)/2 - 1
            smallest = A[j]         (n-1)(n+2)(n-1)/2 - 1
            idx = j                 (n-1)(n+2)(n-1)/2 - 1
    // exchange
    A[idx] = A[i]                   n-1
    A[i] = smallest                 n-1

best-case: theta(n^3)
worst-case: theta(n^3)


2.2-3 linear search analysis
E(x) = (n+1)/2
worst case: n  theta(n)
average-case: theta(n)


2.2-4 
How can we modify almost any algorithm to have a good best-case running time?

We can choose from a wide range of algorithm design techniques. For insertion
sort, we used an incremental approach: having sorted the subarray A[1..j-1], we
inserted the single element A[j] into its proper place, yielding the sorted
subarray A[1..j].
   
In this section, we examine an alternative design approach, know as "divide-and
-conquer", which we shall explore in more detail in Chapter 4.  We'll use 
divide-and-conquer to design a sorting algorithm whose worst-case running time
is much less than that of insertion sort. On advantage of divide-and-conquer
algorithms is that their running times are often easily determined using
techniques that we will see in Chapter 4.

2.3-1

