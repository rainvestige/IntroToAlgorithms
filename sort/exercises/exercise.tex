\documentclass[a4paper, 11pt, UTF8]{article}

\usepackage{amsmath}
\usepackage{bbding}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[dvipsnames]{xcolor}


\title{Exercises (Chapter 2)}
\author{Xinyu Xiao}
\date{\today}


\begin{document}
\maketitle

\section*{2.3-4}
We can express insertion sort as a recursive procedure as follows. In order to
sort $A[1...n]$, we recursively sort $A[1..n-1]$ and then insert $A[n]$ into 
the sorted array $A[1...n-1]$. Write a recurrence for the running time of this
recursive version of insertion sort.


\begin{algorithm}
    \caption{recursive insertion sort}
    \begin{algorithmic}[1]
        \Function {recursive\_insertion\_sort}{A}
        \State {$n = A.length$}
        \If { $n > 1$}
        \State {recursive\_insertion\_sort($A[1..n-1]$)}
        \State {insert($A[1..n-1], A[n]$)}
        \EndIf
        \EndFunction
    \end{algorithmic}
\end{algorithm}


\begin{align*}
    T(n) = 
    \left \lbrace 
    \begin{matrix}
        \Theta(1) & if \; n = 1 \\
        T(n-1) + \Theta(n) & if \; n > 1
    \end{matrix}
    \right . \\
    Let \; \Theta(1) = c \Rightarrow T(n) = \frac{c}{2}(n^2 + n) \\
\end{align*}


\section*{2.3-5}
Refering back to the searching problem(see Exercise 2.1-3), observe that if the
sequence A is sorted, we can check the midpoint of the sequence against 
$\mathcal{V}$ and eliminate half of the sequence from further consideration.
The \emph{binary search} algorithm repeats this procedure, halving the size of
the remaining portion of the sequence each time. Write pseudocode, either
iterative or recursive, for binary search. Argue that the worst-case running
time of binary search is  $\Theta(lgn)$.


\begin{algorithm}
    \caption{binary search $ \to \Theta(lgn)$}
    \begin{algorithmic}[1]
        \Require{sorted array A(incremental), the start and end index p,q
        search value $\mathcal{V}$ }
        \Ensure{the index $i$ such that $A[i] = \mathcal{V}$ or the special 
        value "NIL" if $\mathcal{V}$ does not appear in A}

        \Function{BinarySearch}{$A, p, q, v$}
            \If {$A[p] > v$ \textbf{Or} $A[q] < v$ }
                \State  \Return {$NIL$}
            \EndIf
            \State  $mid = \lfloor \frac{p+q}{2} \rfloor$ 
            \If { $A[mid] < v$ }
                \State \Return \Call{BinarySearch}{$A, mid+1, q, v$ }
            \ElsIf { $A[mid] > v$ }
                \State \Return \Call{BinarySearch}{$A, p, mid-1, v$ }
            \Else
                \State \Return {$mid$}
            \EndIf
        \EndFunction
    \end{algorithmic}
\end{algorithm}


\section*{2.3-6}
Observe that the \textbf{while} loop of lines $5-7$ of the INSERTION-SORT
procedure in Section $2.1$ uses a linear search to scan (backward) through the
sorted subarray $A[1..j-1]$. Can we use a binary search(see Exercise  $2.3-5$ )
instead to improve the overall worst-case running time of insertion sort to 
$\Theta(nlgn)$?

No, we can't. Because we need to shift the whole subarray 
$A[k..j=1], \; \text{such that} \; A[k-1] < key < A[k]$ right one index. The
running time was still $\Theta(n^2)$


\section*{2.3-7 \FiveStar}
Describe a $\Theta(nlgn)$-time algorithm that, given a set $S$ of $n$ integers and
another integer $x$, determines whether or not there exist two elements in $S$ 
whose sum is exactly $x$.

\begin{algorithm}
    \begin{algorithmic}[1]
    \Require { A set $S$ of $n$ integers and another integer $x$ }
    \Ensure { whether or not there exist two elements in $S$ whose sum is 
    exactly $x$.}
    \Function{FindElements}{$S, n, x$}
    \State \Call {MergeSort}{$S, 0, S.length$ }
        \For {$i = 0 \; \textbf{To} \; S.length$}
            \State $v = x - S[i]$ 
            \State $\text{Get the}\; S\_extra$
            \State \Call {BinarySearch}{$S\_extra, 0, S\_extra.length, v$}
        \EndFor
    \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \begin{algorithmic}[1]
    \Require { A set $S$ of $n$ integers and another integer $x$ }
    \Ensure { whether or not there exist two elements in $S$ whose sum is 
    exactly $x$.}
    \Function{FindElements}{$S, n, x$}
        \State \Call {MergeSort}{$S, 0, S.length$ }
        \State $i = 0$ 
        \State $j = n-1$
        \While {$i < j$ }
            \If {$S[i] + S[j] = x$ }
                \State \Return {true}
            \EndIf
            \If {$S[i] + S[j] < x$ }
                \State $i = i + 1$
            \EndIf
            \If {$S[i] + S[j] > x$ }
                \State $j = j - 1$
            \EndIf
        \EndWhile
        \State \Return {false}
    \EndFunction
    \end{algorithmic}
\end{algorithm}


\section*{2-1 Insertion sort on small arrays in merge sort}
Although merge sort runs in $\Theta(nlgn)$ worst-case time and insertion sort
runs in $\Theta(n^2)$ worst-case time, the constant factors in insertion sort 
can make it faster in practice for small problem sizes on many machines. Thus,
it makes sense to \textbf{coarsen} the leaves of the recursion by using 
insertion sort within merge sort when subproblems become sufficiently small.
Consider a modification to merge sort in which $\frac{n}{k}$ sublists of length 
$k$ are sorted using insertion sort and then merged using the standard merging
mechanism, where $k$ is a value to be determined.

\begin{enumerate}
    \item Show that insertion sort can sort the $\frac{n}{k}$ sublists, each of
        length $k$, in $\Theta(nk)$ worst-case tim.

        Insertion sort applied on the sublist of length $k$ runs in 
        $\Theta(k^2)$ worst-case time. We have $\frac{n}{k}$ sublists, so the 
        running time will be $\Theta(\frac{n}{k}*k^2 = \Theta(nk)$.

    \item Show how to merge the sublists in $\Theta(n\log(\frac{n}{k}))$ 
        worst-case time.

        each layer will take $\Theta(n)$ worst-case time, we have $\log(\frac{n}{k})$
        layers, so the merge will take $\Theta(n\log(\frac{n}{k}))$ worst-case 
        time.

        Suppose we have coarseness $k$. This means we can just start using the
        usual merging procedure, except starting it at the level in which each
        array has size at most $k$. This means that the depth of the merge 
        tree is $lg(n) - lg(k) = lg(n/k)$. Each level of merging is still time
        $cn$, so putting it together, the merging takes time $\Theta(nlg(n/k))$.

    \item Given that the modified algorithm runs in $\Theta(nk+n\log( \frac{n}{k}))$
        worst-case time, what is the largest value of $k$ as a function of $n$ 
        for which the modified algorithm has the same running time as standard
        merge sort, in terms of $\Theta$-notation?

        $k < \log(n)$

        Viewing k as a function of n, as long as $k(n) \in O(lg(n))$, it has 
        the same asymptotics. In particular, for any constant choice of k, the
        asymptotics are the same.
        
    \item How should we choose $k$ in practice?
        
\end{enumerate}


\section*{2-2 Correctness of bubblesort}


\section*{2-3 Correctness of Horner's rule}

\begin{enumerate}
    \item In term of $\Theta$-notation, what is the running time of this code
        fragment for Horner's rule?

        $\Theta(n)$ 

    \item Write pseudocode to implement the naive polynomial-evaluation 
        algorithm that computes each term of the polynomial from scratch. What
        is the running time of this algorithm? How does it compare to Horner's
        rule?

        \begin{algorithm}
        \begin{algorithmic}
            \Function {EvaluatePolynomial}{$A, x$ }
            \State $n = A.length - 1$ 
            \State $y = 0$ 
            \For {$k = 0$ \text{to} $n$} 
                \State $temp = 1$
                \State  $j = k$
                \While { $j > 0$ }
                    \State $temp = x * temp$
                    \State  $j = j - 1$
                \EndWhile
                \State $y = A[k] * temp$
            \EndFor
            \State \Return $y$
            \EndFunction
        \end{algorithmic}
        \end{algorithm}

        The running time of this algorithm is $\Theta(n^2)$. Compare with 
        Horner's  rule of runnint time $\Theta(n)$, it is not so good.
    \item Consider the following loop invariant:

        At the \textcolor{red}{start of each iteration} of the \textbf{for} loop of line
        $2-3$,
        \[
            y = \sum\limits_{k = 0}^{n - (i+1)} a_{k+i+1} x^k
        \]
        Interpret a summation with no terms as equaling 0. Following the 
        structure of the loop invariant proof presented in this chapter, use 
        this loop invariant to show that, at termination, $y = \sum_{k = 0}O^n a_k x^k$ 

        Initially, $i=n$, so, the upper bound of the summation is $-1$, so the
        sum evaluates to 0, which is the value of $y$. ...

    \item Conclude by arguing that the given code fragment correctly evaluates
        a polynomial characterized by the coefficients $a_0, a_1, \dots, a_n$.

        We just showed that the algorithm evaluated $\sum_{k=0}^n a_k x^k$. This
        is the value of the polynomial evaluated at $x$
\end{enumerate}


\section*{2-4}
Let $A[1..n]$ be an array of $n$ distinct numbers. If $i<j$ and $A[i] > A[j]$, 
then the pair $(i, j)$ is called an \textbf{inversion} of A.

\begin{enumerate}
    \item List the five inversions of the array $<2, 3, 8, 6,1>$.

        $(0, 4), (1, 4), (2, 3), (2, 4), (3, 4)$

    \item What array with elements from the set  $\{1, 2, \dots, n\}$ has the most
        inversions?

        $<n, n-1, \dots, 1>$
    \item What is the relationship between  the running time of insertion sort
        and the number of inversions in the input array? Justify your answer.

        The more the number of inversions in the input array, the worst the 
        running time of insertion sort.

    \item Give an algorithm that determines the number of inversions in any 
        permutation on $n$ elements in $\Theta(nlgn)$ worst-case time. (Hint:
        Modify merge sort.)

\end{enumerate}

\end{document}


